---
title: '概率建模与推断（4）—— 概率图模型（未完成草稿）'
date: 2019-02-17
permalink: /posts/2019/02/pmr-4/
tags:
  - Chinese
  - Probabilistic Modeling and Reasoning
  - Machine Learning
---

> 作者：Michael Gutmann（迈克尔·古特曼）\\
  译者：郭尚敏（Shangmin Guo），shawnguo.cn@gmail.com \\
  版权声明：本系列博客翻译自作者 [迈克尔·古特曼](https://michaelgutmann.github.io/) 在爱丁堡大学（The University of Edinburgh）2019春季学期“概率建模与推断”（Probabilistic Modelling and Reasoning，INFR11134）课程的授课课件。译者已经取得原作者的翻译授权。

## 0. 扼要回顾

在前面我们主要讲述了以下几个方面的内容：
- 统计独立性假设可以通过减少直接相互作用的变量数量促进了概率模型的有效（efficient）表示；
- 统计独立性可以导出着pdfs/pmfs的因式分解；
- 有序马尔科夫性与因式分解是等价的；
- 以此为基础，我们可以将pdfs/pmfs可视化为有向图。

本篇中，我们将主要讲述以下几个问题：
1. 有向图模型的定义
 - 通过基于图的因式分解定义
 - 通过有序马尔科夫性定义
 - 如何在不同拓扑序的有序马尔科夫性中导出独立性
2. 有向无环图中三种典型连接方式及其性质
 - 串行连接（Serial Connection）
 - 分叉连接（Diverging Connection）
 - 合并连接（Converging Connection）
 - 独立等价性
3. 有向图模型中的独立性
 - D-分离与独立图
 - 有向局部马尔科夫性
 - 不同马尔科夫性与因式分解直接的等价性
 - 马尔科夫覆盖

## 1. 有向图模型的定义

### 1.1. 有向图模型的定义

在前一篇文章中，我们说到，给定一个pdf/pmf，假设其可以根据某种顺序进行因式分解，那么我们可以以此为基础得出等价的DAG（有向无环图）。那么，该过程是否可以反过来呢？答案是，可以的。

在此，我们给出有向图模型的定义如下：

> 一个基于有$d$个节点DAG并对应一系列随机变量$x_i$的有向图模型是指，可以按照如下方式进行因式分解的pdfs/pmfs的集合：
> $$p\left( x_1, \dots, x_d \right) = \prod_{i=1}^{d} p(x_i|pa_i)$$
> 其中$pa_i$代表图中节点$x_i$的所有父节点。

下面举个例子进行说明。比如说，我们有如下DAG：
![FIG4.1](https://i.loli.net/2019/02/18/5c69b8f306640.jpg "FIG4.1")

那么这里有随机变量$a,z,q,e,h$，图中节点的父节点集合分别为：$ pa_a = pa_z = \varnothing, pa_q = \left\\{ a,z \right\\}, pa_e = \left\\{ q \right\\}, pa_h =\left\\{ z \right\\}$。那么由该DAG定义的所有模型均可按照如下方式进行因式分解：
$$p(a,z,q,e,h) = p(a)p(z)p(q|a,z)p(e|q)p(h|z)$$

### 1.2. 通过有序马尔科夫性定义

之前的文章中，我们曾提到，对于一个$d$个节点的DAG，我们总是能找到对应随机变量的一个拓扑序，记为$x_1, \dots, x_d$。并且，我们知道，在拓扑序中，所有的父节点都出现在子节点之前，所以有$pa_i \subseteq pre_i$ （其中，$ pre_i = \left\\{ x_1, \dots, x_{i-1} \right\\} $）.

由有序马尔科夫性与因式分解之间的等价性，我们知道：

$$\prod_{i=1}^{d} p(x_i|pa_i) \Longleftrightarrow x_i ⫫ \left\{ pre_i \setminus pa_i \right\} | pa_i\ \forall\ i$$

> 备注：在之前的文章中，我们使用的是几号$pi_i$，在这里替换为$pa_i$。

这样一来，我们就可以基于有序马尔科夫性给出一个类似于[1.1.节]的有向图模型的定义，如下：
> 一个基于有$d$个节点DAG并对应一系列随机变量$x_i$的有向图模型是指，满足如下有序马尔科夫性的pdfs/pmfs的集合：
> $$x_i ⫫ \left\{ pre_i \setminus pa_i \right\} | pa_i \ \forall\ i$$
> 其中所有变量的排序$x_1, \dots, x_d$都是该DAG的拓扑序。
> 备注：符号含义仍然与之前文章保持一致，即$pre_i$是所有拓扑序中$x_i$的所有前序节点、$pa_i$是图中节点$x_i$的所有父节点。

同样以[1.1.节]中的有向图为例，图中表示的随机变量为$a,z,q,e,h$，在此我们先给出一个拓扑序$\left(a,z,q,e,h \right)$（也就是说，$x_1=a, x_2=z, x_3=q, x_4=e, x_5 = h$），那么我们可以的得到图中每一个节点的前序节点如下：

$$pre_a = \varnothing, pre_z = \left\{ a \right\}, pre_q = \left\{ a,z \right\}, pre_e = \left\{ a,z,q \right\}, pre_h = \left\{ a,z,q,e \right\}$$

图中节点的父节点仍然保持不变：

$$pa_a = pa_z = \varnothing, pa_q = \left\{ a,z \right\}, pa_e = \left\{ q \right\}, pa_h = \left\{z \right\}$$

那么，我们可以得出结论，[1.1.节]中DAG定义的所有模型均满足$ x_i ⫫ \left\\{ pre_i \setminus pa_i \right\\} \| pa_i $， 即：

$$z⫫a \quad e⫫\left\{ a,z \right\}|q \quad h⫫\left\{ a,q,e \right\}|z$$

注意，在上述例子的一开始我们就**给出了一个拓扑序$\left(a,z,q,e,h \right)$**，之后所有的推导都以这个拓扑序为基础。这么做的原因是，**同一个DAG，不同的拓扑序会得到不一样的有序马尔科夫性**。比如说，我们来看另一个[1.1.节](### 1.1. 有向图模型的定义)中DAG的拓扑序$\left( a,z,h,q,e \right)$（交换了之前拓扑序中$h$与$q,e$的顺序），那么节点的前序集合此时为：

$$pre_a = \varnothing, pre_z =  \left\{  a \right\}, pre_h =  \left\{  a,z \right\}, pre_q =  \left\{  a,z,h \right\}, pre_e =  \left\{  a,z,h,q \right\}$$

节点的父节点仍旧保持不变：

$$pa_a = pa_z = \varnothing, pa_q = \left\{ a,z \right\}, pa_e = \left\{ q \right\}, pa_h = \left\{ z \right\}$$

此时，所有按此DAG定义的模型均满足$ x_i ⫫ \left\\{ pre_i \setminus pa_i \right\\} \| pa_i $， 即：

$$z⫫a \quad h⫫a|z \quad q⫫h| \left\{ a,z \right\}  \quad e⫫ \left\{ a,z,h \right\}|q$$

注意，尽管此时我们得到了一系列不同的条件独立性，但**此时的模型仍需要满足的条件独立性**。

### 1.3. 短论
- 由于DAG中每一个节点并不是连接到其所有的前序节点，也就是$pa_i \subseteq pre_i$，才导出来条件独立性。
- 有向图模型都对应于**概率分布**的一个集合。根据两种定义，会有两种观点：集合中包括所有可以通过以下方式得到的分布：
	 - 遍历所有可能的条件概率$ p(x_i \| pa_i) $；
	 - 遍历$x_i$所有可能的联合分布，仅保留满足由图中有序马尔科夫性指定的独立性条件的分布。
- 一般来说，带有指定条件的有向图模型也被简称为有向图模型；（A directed graphical model with specified conditionals is typically also called a directed graphical model.）
- 针对同一个DAG，使用不同的拓扑序可能会导出不同的模型需满足的独立性关系。

### 1.4. 有向图模型的几个例子

#### 1.4.1. 马尔科夫模型
DAG：
[![FIG4.2](https://i.loli.net/2019/02/18/5c69ba35c3d53.jpg "FIG4.2")]("FIG4.2")

所有该图指定的模型都可以因式分解为：
$$p(x) = p(x_1)p(x_2|x_1)p(x_3|x_2)p(x_4|x_3)p(x_5|x_4)$$

由于此图有且只有一个拓扑序——$\left( x_1, x_2, \dots, x_5 \right)$。根据有序马尔科夫性可以得出结论：所有该图指定的模型均满足：
$$x_{i+1}⫫ \left\{ x_1, \dots, x_{i-1} \right\} | x_i$$

> 当给定了现在的状态，未来就与过去无关了。（Future independent of the past given the present.）

#### 1.4.2 概率主成分分析、因子分析与独立成分分析
> 缩写表： 概率主成分分析—PPCA、独立成分分析—ICA

DAG：
[![FIG4.3](https://i.loli.net/2019/02/18/5c69ba6cda295.jpg "FIG4.3")]("FIG4.3")

观测变量$y_i$的性质可以通过更少的隐层变量$x_i$解释。当然，不同的更深入的假设会导出不同的方法，即PPCA、因子分析、ICA都在此图基础上做了更深入的独立性假设。

根据上图及前面的结论，我们知道，所有该图定义的模型可以进行如下的因式分解：
$$p(x_1, x_2, x_3, y_1, \dots, y_5) = p(x_1)p(x_2)p(x_3)p(y_1|x_1, x_2, x_3)\dots p(y_5|x_1,x_2,x_3)$$

如果给定拓扑序$(x_1, x_2, x_3, y_1, y_2, y_3, y_4, y_5)$，那么所有的模型都需满足：

$$
\begin{aligned}
& x_i⫫x_j \quad y_2⫫y_1|\left\{ x_1,x_2,x_3 \right\} \quad y_3⫫\left\{ y_1,y_2 \right\}|\left\{ x_1,x_2,x_3 \right\} \\
& y_4⫫\left\{ y_1,y_2,y_3 \right\}|\left\{ x_1,x_2,x_3 \right\} \quad y_4⫫\left\{ y_1,y_2,y_3,y_4 \right\}|\left\{ x_1,x_2,x_3 \right\}
\end{aligned}
$$

### 1.5. 更多关于独立性的思考
首先，我们简单总结一下之前的内容重点：
- 图中父子节点之间的连接表达了（条件）独立的性质；
- 有序马尔科夫性给出了一系列独立性断言。

基于以上两点，我们提出了以下问题：
- 对于任意一个随机变量三元组 $(x,y,z)$，我们如何判断$ x⫫y\|z $是否成立？
- 图本身是否会比其对应的概率分布因式分解表达更多或更少的独立性？

这个问题之所以重要，主要是因为：
- 能加深我们对模型性质的理解
- 从而使得我们能充分利用这些独立性，在推断和学习的时候

具体的方法是：
观察研究获得一个节点的概率信息（probabilistic evidence）后，其会如何在DAG中”流动“（flow）并影响其他节点的置信度。

## 2. 有向无环图中三种典型连接方式及其性质

这一节中，我们讨论的主要问题为，DAG中的连接方式，以及其对条件独立性产生的影响。

> 译者注：前一节中，我们提到的“概率信息”/“概率证据”在图上的流动其实就是当我们知道某个节点的取值或者概率分布之后，会对依赖于这个变量的其他变量的分布产生怎样的影响。


### 2.1. DAG中的三种典型连接方式
在一个DAG中，两个节点$x$和$y$，可以通过以下三种方式被第三个节点$z$连接：
1. 串行连接（Serial Connection），也称为链式（Chain）、头-尾（head-tail）、尾-头（tail-head）连接，其对应有向图如下：

   [![FIG4.4](https://i.loli.net/2019/02/18/5c69babfcb828.jpg "FIG4.4")]("FIG4.4")

2. 分叉连接（Diverging Connection），也称为叉式（fork）、尾-尾（tail-tail）连接，其对应有向图如下：

   [![FIG4.5](https://i.loli.net/2019/02/18/5c69bad46462a.jpg "FIG4.5")]("FIG4.5")

3. 合并连接（Converging Connection），也称为对撞（collider）、头-头（head-head）、V形（v-structure）连接，其对应有向图如下：

   [![FIG4.6](https://i.loli.net/2019/02/18/5c69bae431f3b.jpg "FIG4.6")]("FIG4.6")
   
注意，无论什么情况下，$x,y,z$都构成了一条路径。

### 2.2 串行连接（Serial Connection）

[![FIG4.4](https://i.loli.net/2019/02/18/5c69babfcb828.jpg "FIG4.4")]("FIG4.4")

通常来说，马尔科夫模型就是由串行连接组成的。

> 译者注：一阶马尔科夫模型。

从图上来说，$x$会影响$z$的取值，从而**间接**影响到$y$的取值。但是，$x$并没有直接影响到$y$。

从因式分解的角度来说，则是$p(x,y,z) = p(x)p(z\|x)p(y\|z)$。

由此，我们也可以说，有如下有序马尔科夫性：$y⫫x\|z$。

也就是，如果$z$的状态或者取值已知（即随机变量$z$已经被“实例化”），那么有关$x$的证据**不会**改变我们对于$y$的取值的信念（belief），反之亦然。这种情况下，我们称节点$z$是**关闭的**（closed），同时称$x$和$y$之间的路径被实例化的$z$所**阻塞**（blocked）。或者说，知道$z$的值会**阻塞**$x$和$y$之间的证据流动。

接下来，我们考虑$(x,y)$的边际分布。通过求和法则，$(x,y)$的联合分布如下：

$$
\begin{aligned}
p(x,y) & = \int p(x)p(z|x)p(y|z)dz \\
       & = p(x) \int p(z|x)p(y|z)dz \\
       & \neq p(x)p(y)
\end{aligned}
$$

> 译者注：也就是，$x$和$y$在$z$取值未知时，并不是相互独立的。

所以，在一个串行连接中，如果$z$的状态未知，那么关于$x$的证据或者信息并**会**影响我们对于$y$的取值的信念，反之也成立。此时，证据能够通过$z$在$x$和$y$之间流动，我们称节点$z$是**开放的（opened）**，同时$x$和$y$之间的路径是**活跃的（active)**.

### 2.3 分叉连接（Diverging Connection）

[![FIG4.5](https://i.loli.net/2019/02/18/5c69bad46462a.jpg "FIG4.5")]("FIG4.5")

我们后面会提到，概率PCA、因子分析、独立成分分析模型中均有这种连接。其中，$z$对应着隐变量，$x$和$y$对应着观测到的变量。

从图上来看，$z$会影响到$x$和$y$，但之间并没有直接连接。

从因式分解的角度来说，则是$p(x,y,z) = p(z)p(x\|z)p(y\|z)$。

由此，我们也可以说，有如下有序马尔科夫性（顺序为$z, x, y$）：$y⫫x\|z$。

也就是，如果$z$的状态或者取值已知（即随机变量$z$已经被“实例化”），那么有关$x$的证据**不会**改变我们对于$y$的取值的信念（belief），反之亦然。与串行连接相同，知道$z$的取值，会关闭节点$z$并**阻塞**$x$和$y$之间的路径。

接下来，我们考虑$(x,y)$的边际分布。通过求和法则，$(x,y)$的联合分布如下：

$$
\begin{aligned}
p(x,y) & = \int p(z)p(x|z)p(y|z)dz \\
       & \neq p(x)p(y)
\end{aligned}
$$

所以，在一个分叉连接中，跟串行连接一样，如果$z$的状态未知，那么关于$x$的证据或者信息并**会**影响我们对于$y$的取值的信念，反之也成立。此时，证据能够通过$z$在$x$和$y$之间流动，我们称节点$z$是**开放的（opened）**，同时$x$和$y$之间的路径是**活跃的（active)**.

### 2.4 合并连接（Converging Connection）

[![FIG4.6](https://i.loli.net/2019/02/18/5c69bae431f3b.jpg "FIG4.6")]("FIG4.6")

# To Be Continued