---
title: '概率建模与推断（2）—— 高效模型表示的基本假设'
date: 2019-02-15
permalink: /posts/2019/02/pmr-2/
tags:
  - Chinese
  - Probabilistic Modeling and Reasoning
  - Machine Learning
---

> 作者：Michael Gutmann（迈克尔·古特曼）\\
  译者：郭尚敏（Shangmin Guo），shawnguo.cn@gmail.com \\
  版权声明：本系列博客翻译自作者 [迈克尔·古特曼](https://michaelgutmann.github.io/) 在爱丁堡大学（The University of Edinburgh）2019春季学期“概率建模与推断”（Probabilistic Modelling and Reasoning，INFR11134）课程的授课课件。译者已经取得原作者的翻译授权。

## 0.  扼要回顾

在前面，我们的求解目标为

$$
p(\mathbf{x}|\mathbf{y}_o) = \frac{\sum_{\mathbf{z}} p(\mathbf{x}, \mathbf{y}_o, \mathbf{z})}{\sum_{\mathbf{x}, \mathbf{z}} p(\mathbf{x}, \mathbf{y}_o, \mathbf{z})}
$$。


假设$\mathbf{x}, \mathbf{y}, \mathbf{z}$均为$d=500$维向量且向量中每个元素可取$K=10$个离散值， 那么会带来第一个 问题：为了指定$p(\mathbf{x}, \mathbf{y}, \mathbf{z})$，我们需要指定$K^{3d}-1=10^{1500}-1$个非负数。这样的计算量明显是不可行的。所以，就引出了我们的第一个主题——表示：为了有效地（efficiently）表示$p(\mathbf{x}, \mathbf{y}, \mathbf{z})$，我们可以做哪些合理的弱假设？

在PMR中我们主要考虑以下两种假设：
1. 独立性假设（independence assumptions）：只有有限数量的变量会直接互相作用（interact）；
2. 参数族假设（parametric family assumptions）：对于任何直接相互作用的变量来说，其相互作用的形式是固定的或有限的。

> 这两条假设可以同时使用，也可以独立使用

## 1.  独立性假设

在本节中，我们将讨论一下两个问题：
1. 统计独立性的定义与性质
2. PDF的因式分解与直接相互作用变量数目的缩减

> 在后续篇章中，如果不做特别注释，所有变量符号，如$x$、$y$等，均表示向量。

### 1.1. 统计独立性的定义与性质回顾
假设$x$和$y$是两个不相交的随机变量集合，称$x$和$y$相互独立，当且仅当

$$p(x,y) = p(x)p(y) \forall x, y$$。

否则就称这两个子集相关（非独立）。

同时，我们可以称上述公式为：联合分布可以*因式分解*为$p(x)$和$p(x)$。结合乘积法则可知：

$$
p(x|y) = \frac{p(x,y)}{p(y)} = \frac{p(x)p(y)}{p(y)} = p(x)\ \ \forall x, y \ \ \ \text{where}\ \  y>0
$$。

为方便起见，我们记该性质为：$x⫫y$。

对于多变量的情况来说，变量$x_1, \dots, x_n$相互独立当且仅当

$$
p(x_1, \dots, x_n) = \prod_{i=1}^{n}p(x_i)
$$。

### 1.2. 条件统计独立性的定义与性质回顾
以上在1.1.节中所表述的统计独立性的特点均可拓展到条件PDFs（PMFS）$p(x,y|z)$中。

首先，条件独立的基本表达为$p(x,y\|z) = p(x\|z)p(y\|z)$，并且结合乘积法则可知$p(x\|y) = p(x)​$并且$p(x\|y,z)=p(x\|z)$。

我们称$x$和$y$给定$z$时条件独立当且仅当，对于所有$x$、$y$、$z$的可能取值，当$p(z)>0$时，有：

$$
\begin{aligned}
p(x,y|z) &= p(x|z)p(y|z)\ \  \text{or} \\
p(x|y,z) &= p(x|z)\ \ \text{where }\ p(y,z)>0
\end{aligned}
$$

为方便起见，我们记上述性质为：$x⫫y\|z$。

### 1.3. 独立假设的作用
独立假设最关键的作用是可以导出pdf（pmf）部分因式分解。举例说，如果$x$、$y$、$z$相互独立，那么

$$p(x,y,z) = p(x)p(y)p(z)$$。

从上面可以看出，独立假设可以指定$p(x,y,z)$为一个特定形式。

假设$p(x,y,z) = p(x)p(y)p(z)$，可以得出：
- 如果$dim(x) = dim(y) = dim(z) = d$并且每个元素可以取$K$个不同的值，那么因式分解能够将需要指定的参数数量从$K^{3d}-1$减少到$3\left( K^d-1\right) $。
- 进一步说，如果$x$、$y$、$z$中每个元素都是独立的，那么只需要指定$3d(K-1)$个参数。为了更直观地体现数量上的差距，我们再次以$K=10, d=500$为例，那么就是
$$10^{1500}-1\ \text{v.s.}\ 3(10^{500} - 1) \ \text{v.s.}\ 1500(10-1)=13500$$

虽然这样的性质非常方便，但是完全独立是一个非常强的假设，并不经常成立。所以，**条件独立假设**是一个更有效的折中方案。

具体来说，对于$p(x) = p(x_1, \dots, x_d)$，由乘积法则可知：
$$p(x) = p(x_d|x_1, \dots, x_{d-1})p(x_1, \dots, x_{d-1})$$。

如果，我们假设$x_d⫫ \left\\{ x_1, \dots, x_{d-4} \right\\} \| \left\\{ x_{d-3}, x_{d-2}, x_{d-1} \right\\}$，那么可以得出：

$$
p(x_d|x_1, \dots, x_{d-1}) = p(x_d|x_{d-3}, x_{d-2}, x_{d-1})
$$。

仍旧以每个元素$x_i$有$K$个不同的取值为例，那么

- $p(x_d\|x_1, \dots, x_{d-1}) $需要$K^{d-1}\cdot \left(K-1\right)$个数字指定；
- $p(x_d\|x_{d-3}, x_{d-2}, x_{d-1})$则只需要$K^{3}\cdot \left(K-1\right)$个数字指定。
- 如果$d=500, K=10$，那么以上数字对比为$10^{499}\cdot 9 \approx 10^{500}$ v.s. $9000\approx 10^4$。

### 1.4. 小结
通过独立假设，我们可以限制相互作用的变量数量，从而减少概率分布的计算量。

## 2.  参数族假设
核心思想：参数化模型（parametric model）可以限制变量之间如何相互影响。

### 2.1. 独立假设的不足
通过[1.3.](### 1.3. 独立假设的作用)，我们知道（条件）独立假设可以限制相互作用的变量数量，从而大幅减少计算量。比如在上例中，$x_d$只会被$x_{d-3}$、$x_{d-2}$和$x_{d-1}$所影响。

**但是**，$x_d$如何被其他三个变量所以影响，并没有限制，我们可以随意指定其概率分布的数值。

### 2.2. 相互作用形式的限制
为了解决上述问题，我们可以限制给定变量之间相互作用的形式。

比如说，若$x_i \in \\{0,1 \\}$ ，那么我们可以假设$p(x_d|x_{d-3}, x_{d-2}, x_{d-1})$的概率分布满足如下形式：
$$p(x_d=1|x_{d-3}, x_{d-2}, x_{d-1}) = \frac{1}{1+exp\left( -w_0-\sum_{i=1}^{d-1} w_ix_i \right) }$$，
其中有$d$个自由参数$w_0, \dots, w_{d-1}$。

这样一来，我们只需要指定$d$个数字来计算其概率分布。但如果没有这个假设，我们需要穷举所有的组合可能，也就是指定$2^{d-1}$个数字。

## 3. 扼要回顾
在本篇一开始，我们的问题是：我们可以做出哪些合理的弱假设以有效地表示一个概率模型。总结来说，我们阐述了如下问题：

1. 独立性假设
	- 统计独立性的定义与性质
	- pdf（pmf）的因式分解及直接相互作用变量数目的减少

2. 参数族假设
	- 参数化模型可以限制给定变量如何相互影响
